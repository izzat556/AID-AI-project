{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303fde17-ac49-4da4-85a3-86b905953d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"alex_commands.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "training_data = []\n",
    "\n",
    "# Check if JSON is a dict (with \"keywords\") or a list of objects\n",
    "if isinstance(data, dict):\n",
    "    for intent, details in data.items():\n",
    "        for phrase in details.get(\"keywords\", []):\n",
    "            training_data.append({\n",
    "                \"text\": phrase,\n",
    "                \"intent\": intent\n",
    "            })\n",
    "elif isinstance(data, list):\n",
    "    for item in data:\n",
    "        if \"text\" in item and \"intent\" in item:\n",
    "            training_data.append({\n",
    "                \"text\": item[\"text\"],\n",
    "                \"intent\": item[\"intent\"]\n",
    "            })\n",
    "\n",
    "with open(\"intent_training.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(training_data, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"Training dataset created!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bffa96f-ca6d-4676-9ac2-c7980464a1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "import warnings\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "\n",
    "# ----------------------------\n",
    "# Load training data\n",
    "# ----------------------------\n",
    "with open(\"intent_training.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "texts = [item[\"text\"] for item in data]\n",
    "labels = [item[\"intent\"] for item in data]\n",
    "responses = [item.get(\"response\", \"\") for item in data]  # optional response\n",
    "\n",
    "# ----------------------------\n",
    "# Convert text to vectors\n",
    "# ----------------------------\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(texts)\n",
    "\n",
    "# ----------------------------\n",
    "# Train classifier\n",
    "# ----------------------------\n",
    "model = LogisticRegression(max_iter=2000)\n",
    "model.fit(X, labels)\n",
    "\n",
    "# ----------------------------\n",
    "# Evaluate classifier\n",
    "# ----------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, labels, test_size=0.2, random_state=42, stratify=labels\n",
    ")\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Weighted F1 Score: {f1:.4f}\\n\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "cv_scores = cross_val_score(model, X, labels, cv=5, scoring=\"f1_weighted\")\n",
    "print(f\"Cross-validated F1 (weighted): {np.mean(cv_scores):.4f}\")\n",
    "\n",
    "# ----------------------------\n",
    "# Save model, vectorizer, and responses\n",
    "# ----------------------------\n",
    "with open(\"intent_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump({\n",
    "        \"model\": model,\n",
    "        \"vectorizer\": vectorizer,\n",
    "        \"responses\": {item[\"intent\"]: item.get(\"response\", \"\") for item in data}\n",
    "    }, f)\n",
    "\n",
    "print(\"\\nâœ… Intent classifier trained and saved with responses as 'intent_model.pkl'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcab627-aa63-4e2c-826a-cb6b70ddd160",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3e5361-9311-4c95-96e1-7fa708fc41a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdc3090-d32f-4484-baaa-ad964a845a92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ae5642-08d8-4818-b0c5-33c96cd07f2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0074f014-3aa4-4bcf-a0b0-96cab00685bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1728a818-450c-4f4b-8f47-f16074450336",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6608061b-e642-4e76-9d0c-ad0428a2f091",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
